{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from analysis_scripts import analysis_functions\n",
    "from matplotlib import pyplot as plt\n",
    "import ast\n",
    "from matplotlib.sankey import Sankey\n",
    "#\n",
    "# functions used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_number_of_dalys(filename):\n",
    "    \"\"\"A function that takes in a filepath and returns the DALYs in the simulation\"\"\"\n",
    "    # Import data from output file as dataframe\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    # Check the relevant column is in the dataframe columns\n",
    "    assert 'DALYs' in df.columns, 'This file did not record the DALYs caused by COVID in the population'\n",
    "    # Only look at those who have had some health burden caused by COVID (no asymptomatic cases)\n",
    "    df = df.loc[df['DALYs'] != '-']\n",
    "    # Calculate the DALYs caused by COVID\n",
    "    DALYs = df.DALYs.astype(float).sum()\n",
    "    # return the result\n",
    "    return DALYs\n",
    "\n",
    "\n",
    "def calculate_number_of_yll_and_yld(filename):\n",
    "    \"\"\"A function that takes in a filepath and returns the DALYs in the simulation\"\"\"\n",
    "    # Import data from output file as dataframe\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    # Check the relevant column is in the dataframe columns\n",
    "    assert 'YLL' in df.columns, 'This file did not record the YLL caused by COVID in the population'\n",
    "    assert 'YLD' in df.columns, 'This file did not record the YLD caused by COVID in the population'\n",
    "\n",
    "    # Only look at those who have had some health burden caused by COVID (no asymptomatic cases)\n",
    "    yll_df = df.loc[df['YLL'] != '-']\n",
    "    yld_df = df.loc[df['YLD'] != '-']\n",
    "    # Calculate the DALYs caused by COVID\n",
    "    yll = yll_df.YLL.astype(float).sum()\n",
    "    yld = yld_df.YLD.astype(float).sum()\n",
    "\n",
    "    # return the result\n",
    "    return yll, yld\n",
    "\n",
    "\n",
    "def get_distributions_of_number_of_infections_per_source(filename, return_mean_std=False):\n",
    "    \"\"\"A function that takes in a filepath and distribution in the number of infections caused per person, if you want\n",
    "    the average and std of a run, set return_mean_std to be true\"\"\"\n",
    "    # Import data from output file as dataframe\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    # Add a counter column, which will be used to determine the number of infections caused by each host/infection\n",
    "    df['counter'] = [1] * len(df)\n",
    "    # Check that who gave the infection is recorded in the dataframe\n",
    "    assert 'Source' in df.columns, 'This file did not record the Source of each infection'\n",
    "    # Group by who gave out the infection and sum the results\n",
    "    df = df.groupby(by='Source').sum()\n",
    "    # Sort the number of infections caused by each host, from smallest to largest\n",
    "    df = df.sort_values('counter')\n",
    "    # Find the number of infections caused by each host and how many hosts caused each number of infections\n",
    "    number_of_infections, counts = np.unique(df['counter'], return_counts=True)\n",
    "    # Return the range of the number of infections caused by each host, and the corresponding number of hosts who caused\n",
    "    # that number of infections\n",
    "    mean = ''\n",
    "    std = ''\n",
    "    if return_mean_std:\n",
    "        mean = df.counter.mean()\n",
    "        std = df.counter.std()\n",
    "    return (number_of_infections, counts) if not return_mean_std else number_of_infections, counts, mean, std\n",
    "\n",
    "\n",
    "def get_final_infection_status(filename):\n",
    "    \"\"\"A function that takes in a filepath and distribution in the infection status of those with covid\"\"\"\n",
    "    # Import data from output file as dataframe\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    # copy the output file so we can drop rows from it\n",
    "    infectious_pop = df.copy()\n",
    "    # Calculate the number of people who died from their infection\n",
    "    who_died_from_covid = infectious_pop.loc[df['DiedAt'] != '-'].index\n",
    "    n_died = len(who_died_from_covid)\n",
    "    # remove those who died from covid from the infectious_pop df\n",
    "    infectious_pop = infectious_pop.drop(index=who_died_from_covid)\n",
    "    # Calculate the number of people who reached a critical condition\n",
    "    who_reached_critical = infectious_pop.loc[df['CriticalAt'] != '-'].index\n",
    "    n_critical = len(who_reached_critical)\n",
    "    # remove those who reached critical covid from the infectious_pop df\n",
    "    infectious_pop = infectious_pop.drop(index=who_reached_critical)\n",
    "    # Calculate the number of people who had severe covid\n",
    "    who_reached_severe = infectious_pop.loc[df['SevereAt'] != '-'].index\n",
    "    n_severe = len(who_reached_severe)\n",
    "    # remove those who reached severe from infectious_pop\n",
    "    infectious_pop = infectious_pop.drop(index=who_reached_severe)\n",
    "    # Calculate the number of people who had mild covid\n",
    "    who_reached_mild = infectious_pop.loc[df['SymptomaticAt'] != '-'].index\n",
    "    n_mild = len(who_reached_mild)\n",
    "    #  remove those who had mild infection from infectious_pop\n",
    "    infectious_pop = infectious_pop.drop(index=who_reached_mild)\n",
    "    who_was_asymptomatic = infectious_pop.loc[df['SymptomaticAt'] == '-']\n",
    "    # Calculate the proportion of infections that are asymptomatic\n",
    "    n_asymptomatic = len(who_was_asymptomatic)\n",
    "    # Create reference to COVID infection status\n",
    "    infections_by_status = [n_asymptomatic, n_mild, n_severe, n_critical, n_died]\n",
    "    distribution_of_status = list(np.divide(infections_by_status, sum(infections_by_status)))\n",
    "    return distribution_of_status\n",
    "\n",
    "\n",
    "def extract_time_in_each_stage(filename):\n",
    "    \"\"\"A function to get the average time spent in each infection state from the simulation\"\"\"\n",
    "    # Import data from output file as dataframe\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    # Get those who are not asymptomatic\n",
    "    filtered_pop = df.loc[df['SymptomaticAt'] != '-'].copy()\n",
    "    # Drop initial infections from calculations\n",
    "    filtered_pop = filtered_pop.loc[filtered_pop['Time'] != - 1]\n",
    "    # Change data types of columns to int\n",
    "    filtered_pop[['ContagiousAt', 'SymptomaticAt']] = filtered_pop[['ContagiousAt', 'SymptomaticAt']].astype(int)\n",
    "    # Calculate incubation period\n",
    "    filtered_pop['IncubationPeriod'] = filtered_pop['SymptomaticAt'] - filtered_pop['ContagiousAt']\n",
    "    #  Check calculations haven't been messed up\n",
    "    assert (filtered_pop['IncubationPeriod'] > 0).all()\n",
    "    mean_incubation_period = filtered_pop['IncubationPeriod'].mean()\n",
    "    std_incubation_period = filtered_pop['IncubationPeriod'].std()\n",
    "    # get those who are severely ill\n",
    "    filtered_pop = df.loc[df['SevereAt'] != '-'].copy()\n",
    "    # Drop initial infections if any\n",
    "    filtered_pop = filtered_pop.loc[filtered_pop['Time'] != - 1]\n",
    "    # change data type to int\n",
    "    filtered_pop[['SymptomaticAt', 'SevereAt']] = filtered_pop[['SymptomaticAt', 'SevereAt']].astype(int)\n",
    "    # Calculate the interval between being symptomatic and severe\n",
    "    filtered_pop['time_until_severe'] = filtered_pop['SevereAt'] - filtered_pop['SymptomaticAt']\n",
    "    # Calculate mean and std until severe\n",
    "    mean_time_until_severe = filtered_pop['time_until_severe'].mean()\n",
    "    std_time_until_severe = filtered_pop['time_until_severe'].std()\n",
    "    # Get those who are critically ill\n",
    "    filtered_pop = df.loc[df['CriticalAt'] != '-'].copy()\n",
    "    # Drop initial infections if any\n",
    "    filtered_pop = filtered_pop.loc[filtered_pop['Time'] != - 1]\n",
    "    # change data type to int\n",
    "    filtered_pop[['SevereAt', 'CriticalAt']] = filtered_pop[['SevereAt', 'CriticalAt']].astype(int)\n",
    "    # Calculate duration between being severely ill and critically ill\n",
    "    filtered_pop['time_until_critical'] = filtered_pop['CriticalAt'] - filtered_pop['SevereAt']\n",
    "    # Calculate mean and STD\n",
    "    mean_time_until_critical = filtered_pop['time_until_critical'].mean()\n",
    "    std_time_until_critical = filtered_pop['time_until_critical'].std()\n",
    "    # Get those who died\n",
    "    filtered_pop = df.loc[df['DiedAt'] != '-'].copy()\n",
    "    # Drop initial infections if any\n",
    "    filtered_pop = filtered_pop.loc[filtered_pop['Time'] != - 1]\n",
    "    # change data type to int\n",
    "    filtered_pop[['DiedAt', 'CriticalAt']] = filtered_pop[['DiedAt', 'CriticalAt']].astype(int)\n",
    "    # Calculate time between being severly ill and dying\n",
    "    filtered_pop['time_until_death'] = filtered_pop['DiedAt'] - filtered_pop['CriticalAt']\n",
    "    # Calculate mean and std\n",
    "    mean_time_until_death = filtered_pop['time_until_death'].mean()\n",
    "    std_time_until_death = filtered_pop['time_until_death'].std()\n",
    "    # mean transition periods\n",
    "    mean_time_in_each_category = [mean_incubation_period, mean_time_until_severe, mean_time_until_critical,\n",
    "                                  mean_time_until_death]\n",
    "    std_time_in_each_category = [std_incubation_period, std_time_until_severe, std_time_until_critical,\n",
    "                                 std_time_until_death]\n",
    "\n",
    "    # return results\n",
    "    return mean_time_in_each_category, std_time_in_each_category\n",
    "\n",
    "\n",
    "def find_number_who_reached_each_stage_of_disease(filename):\n",
    "    \"\"\"A function which looks at the output of the model and works out which stage of the disease was reached\"\"\"\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    # Find who is contagious\n",
    "    contagious_index = df.loc[df['ContagiousAt'] != '-'].index\n",
    "    # Found how many people were contagious\n",
    "    contagious_count = len(contagious_index)\n",
    "    # Find who recovered from COVID at the contagious stage and how many\n",
    "    recovered_at_contagious_index = df.loc[\n",
    "        contagious_index.intersection(\n",
    "            df.loc[df['SymptomaticAt'] == '-'].index\n",
    "        )\n",
    "    ].index\n",
    "    recovered_at_contagious_count = len(recovered_at_contagious_index)\n",
    "    # Find who developed symptomatic COVID and how many\n",
    "    symptomatic_index = df.loc[df['SymptomaticAt'] != '-'].index\n",
    "    symptomatic_count = len(symptomatic_index)\n",
    "    # Find who recovered from COVID at the symptomatic stage and how many\n",
    "    recovered_at_symptomatic_index = df.loc[\n",
    "        symptomatic_index.intersection(\n",
    "            df.loc[df['SevereAt'] == '-'].index\n",
    "        )\n",
    "    ].index\n",
    "    recovered_at_symptomatic_count = len(recovered_at_symptomatic_index)\n",
    "    # Find who developed severe COVID and how many recovered at this point\n",
    "    severe_index = df.loc[df['SevereAt'] != '-'].index\n",
    "    severe_count = len(severe_index)\n",
    "    # Find who recovered from COVID at the symptomatic stage and how many\n",
    "    recovered_at_severe_index = df.loc[\n",
    "        severe_index.intersection(\n",
    "            df.loc[df['CriticalAt'] == '-'].index\n",
    "        )\n",
    "    ].index\n",
    "    recovered_at_severe_count = len(recovered_at_severe_index)\n",
    "    # Find who developed critical COVID and how many recovered at this point\n",
    "    critical_index = df.loc[df['CriticalAt'] != '-'].index\n",
    "    critical_count = len(critical_index)\n",
    "    # Find who recovered from COVID at the symptomatic stage and how many\n",
    "    recovered_at_critical_index = df.loc[\n",
    "        critical_index.intersection(\n",
    "            df.loc[df['DiedAt'] == '-'].index\n",
    "        )\n",
    "    ].index\n",
    "    recovered_at_critical_count = len(recovered_at_critical_index)\n",
    "    n_died = critical_count - recovered_at_critical_count\n",
    "\n",
    "    counts_at_each_stage = pd.Series(data=[contagious_count, recovered_at_contagious_count, symptomatic_count,\n",
    "                                           recovered_at_symptomatic_count, severe_count, recovered_at_severe_count,\n",
    "                                           critical_count, recovered_at_critical_count, n_died],\n",
    "                                     index=['n_contagious', 'n_recovered_at_contagious', 'n_symptomatic',\n",
    "                                            'n_recovered_at_symptomatic', 'n_severe', 'n_recovered_at_severe',\n",
    "                                            'n_critical', 'n_recovered_at_critical', 'n_died'])\n",
    "    return counts_at_each_stage\n",
    "\n",
    "\n",
    "def get_cum_sum_cases_deaths(filename):\n",
    "    simulation_data_over_time = pd.read_csv(filename, sep=\"\\t\")\n",
    "    # Group the district level information by time\n",
    "    simulation_data_over_time = simulation_data_over_time.groupby('time').sum()\n",
    "    # Total the number of both asymptomatic and symptomatic cases\n",
    "    simulation_data_over_time['new_cases'] = simulation_data_over_time['metric_new_cases_asympt'] + \\\n",
    "                                             simulation_data_over_time['metric_new_cases_sympt']\n",
    "    # Calculate the cumulative sum of cases\n",
    "    simulation_data_over_time['new_cases_cumulative'] = simulation_data_over_time['new_cases'].cumsum()\n",
    "    # return the cumulative sum of cases and deaths\n",
    "    return simulation_data_over_time['new_cases_cumulative'].tolist(), \\\n",
    "           simulation_data_over_time['metric_died_count'].tolist(), simulation_data_over_time['new_cases'].tolist()\n",
    "\n",
    "\n",
    "def get_cases_and_deaths_over_time(filename):\n",
    "    # read in data from file\n",
    "    simulation_data_over_time = pd.read_csv(filename, sep=\"\\t\")\n",
    "    # Calculate total new cases\n",
    "    simulation_data_over_time['new_cases'] = simulation_data_over_time['metric_new_cases_asympt'] + \\\n",
    "                                             simulation_data_over_time['metric_new_cases_sympt']\n",
    "    simulation_data_over_time = simulation_data_over_time.groupby('time').sum()\n",
    "    # Return cases and deaths\n",
    "    return simulation_data_over_time['new_cases'].tolist(), simulation_data_over_time['metric_new_deaths'].tolist()\n",
    "\n",
    "\n",
    "def extract_number_of_districts_with_cases_over_time(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    # calculate number of cases at each time point\n",
    "    sim_time = data.time.unique()\n",
    "    results = pd.DataFrame(index=sim_time)\n",
    "    n_districts_with_covid = []\n",
    "    districts_with_covid = []\n",
    "    for t in data.time.unique():\n",
    "        df = data.loc[data['time'] == t]\n",
    "        districts_with_asymptomatic_cases = list(df.loc[df['metric_new_cases_asympt'] > 0, 'myId'].unique())\n",
    "        districts_with_symptomatic_cases = list(df.loc[df['metric_new_cases_sympt'] > 0, 'myId'].unique())\n",
    "        districts_with_covid_at_t = districts_with_symptomatic_cases + districts_with_asymptomatic_cases\n",
    "        districts_with_covid_at_t = list(np.unique(districts_with_covid_at_t))\n",
    "        n_districts_with_covid_at_t = len(districts_with_covid_at_t)\n",
    "        n_districts_with_covid.append(n_districts_with_covid_at_t)\n",
    "        districts_with_covid.append(districts_with_covid_at_t)\n",
    "    results['n_districts_with_covid'] = n_districts_with_covid\n",
    "    results['districts_with_covid'] = districts_with_covid\n",
    "    results['cumulative_districts'] = results['districts_with_covid'].cumsum()\n",
    "    cumulative_districts_no_duplicates = []\n",
    "    for district_list in results['cumulative_districts']:\n",
    "        cumulative_districts_no_duplicates.append(list(np.unique(district_list)))\n",
    "    results['cumulative_districts'] = cumulative_districts_no_duplicates\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "min_district_start_points = ['_d29_', '_d39_', '_d41_', '_d42_', '_d51_']\n",
    "min_directory = os.fsencode(\n",
    "    '/Users/robbiework/eclipse-workspace/Disease-Modelling-SSA/java/WorldBankCovid19/outputs/'\n",
    "    'different_district_start_points_min/'\n",
    ")\n",
    "for start_point in min_district_start_points:\n",
    "    data = pd.DataFrame()\n",
    "    run_count = 0\n",
    "    for idx, file in enumerate(os.listdir(min_directory)):\n",
    "        filename = os.fsdecode(file)\n",
    "        filepath = min_directory.decode() + filename\n",
    "        if (\"infect\" not in filename) and (start_point in filename):\n",
    "            data_intro = pd.read_csv(filepath, delimiter='\\t')\n",
    "            if run_count == 0:\n",
    "                orig_index = pd.DataFrame()\n",
    "                orig_index['time'] = data_intro['time']\n",
    "                orig_index['myId'] = data_intro['myId']\n",
    "            else:\n",
    "                assert list(orig_index.time) == list(data_intro.time)\n",
    "                assert list(orig_index.myId) == list(data_intro.myId)\n",
    "\n",
    "            run_count += 1\n",
    "\n",
    "            data = pd.concat([data, data_intro]).groupby(level=0).mean()\n",
    "            if run_count == 30:\n",
    "                data['myId'] = orig_index['myId']\n",
    "            data.to_csv(f\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/data/\"\n",
    "                        f\"start_at{start_point}output.csv\")\n",
    "max_directory = os.fsencode(\n",
    "    '/Users/robbiework/eclipse-workspace/Disease-Modelling-SSA/java/WorldBankCovid19/outputs/'\n",
    "    'different_district_start_points/'\n",
    ")\n",
    "max_district_start_points = ['_d2_', '_d18_', '_d23_', '_d26_', '_d31_']\n",
    "for start_point in max_district_start_points:\n",
    "    data = pd.DataFrame()\n",
    "    run_count = 0\n",
    "    for idx, file in enumerate(os.listdir(max_directory)):\n",
    "        filename = os.fsdecode(file)\n",
    "        filepath = max_directory.decode() + filename\n",
    "        if filename.startswith(\"district_start_point\" + start_point):\n",
    "            data_intro = pd.read_csv(filepath, delimiter='\\t')\n",
    "            if run_count == 0:\n",
    "                orig_index = pd.DataFrame()\n",
    "                orig_index['time'] = data_intro['time']\n",
    "                orig_index['myId'] = data_intro['myId']\n",
    "            else:\n",
    "                assert list(orig_index.time) == list(data_intro.time)\n",
    "                assert list(orig_index.myId) == list(data_intro.myId)\n",
    "\n",
    "            run_count += 1\n",
    "\n",
    "            data = pd.concat([data, data_intro]).groupby(level=0).mean()\n",
    "            if run_count == 30:\n",
    "                data['myId'] = orig_index['myId']\n",
    "            data.to_csv(f\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/data/\"\n",
    "                        f\"start_at{start_point}output.csv\")\n",
    "\n",
    "\n",
    "\n",
    "min_directory = os.fsencode(\n",
    "    '/Users/robbiework/eclipse-workspace/Disease-Modelling-SSA/java/WorldBankCovid19/outputs/'\n",
    "    'different_district_start_points_min/'\n",
    ")\n",
    "\n",
    "min_results_df = pd.DataFrame()\n",
    "min_results_df.index = ['DALYs', 'YLL', 'YLD', 'mean_infected_per_host', 'dist_inf_status', 'cumulative_cases',\n",
    "                        'n_cases', 'up', 'low', 'cumulative_deaths', 'n_deaths']\n",
    "\n",
    "for start_point in min_district_start_points:\n",
    "    dalys_per_run = []\n",
    "    yld_per_run = []\n",
    "    yll_per_run = []\n",
    "    n_infected_per_host = []\n",
    "    countinfected_per_host = []\n",
    "    mean_n_infected_per_host = []\n",
    "    distribution_of_infection_status = []\n",
    "    mean_time_spent_in_each_status = []\n",
    "    std_time_spent_in_each_status = []\n",
    "    disease_progression_df = pd.DataFrame()\n",
    "    cumsum_cases = []\n",
    "    cumsum_deaths = []\n",
    "    daily_cases = []\n",
    "    daily_deaths = []\n",
    "    n_cases = []\n",
    "    for idx, file in enumerate(os.listdir(min_directory)):\n",
    "        filename = os.fsdecode(file)\n",
    "        filepath = min_directory.decode() + filename\n",
    "\n",
    "        if start_point in filename:\n",
    "            if 'infect' in filename:\n",
    "                dalys_per_run.append(calculate_number_of_dalys(filepath))\n",
    "                yll_per_run.append(calculate_number_of_yll_and_yld(filepath)[0])\n",
    "                yld_per_run.append(calculate_number_of_yll_and_yld(filepath)[1])\n",
    "\n",
    "                n_infected_per_host.append(\n",
    "                    get_distributions_of_number_of_infections_per_source(filepath,\n",
    "                                                                                            return_mean_std=True)[0]\n",
    "                )\n",
    "                countinfected_per_host.append(\n",
    "                    get_distributions_of_number_of_infections_per_source(filepath,\n",
    "                                                                                            return_mean_std=True)[1]\n",
    "                )\n",
    "                mean_n_infected_per_host.append(\n",
    "                    get_distributions_of_number_of_infections_per_source(filepath,\n",
    "                                                                                            return_mean_std=True)[2]\n",
    "                )\n",
    "                distribution_of_infection_status.append(get_final_infection_status(filepath))\n",
    "                mean_time_spent_in_each_status.append(extract_time_in_each_stage(filepath)[0])\n",
    "                std_time_spent_in_each_status.append(extract_time_in_each_stage(filepath)[1])\n",
    "                disease_progression_df[idx] = find_number_who_reached_each_stage_of_disease(filepath)\n",
    "            else:\n",
    "                cumsum_cases.append(get_cum_sum_cases_deaths(filepath)[0])\n",
    "                cumsum_deaths.append(get_cum_sum_cases_deaths(filepath)[1])\n",
    "                n_cases.append(get_cum_sum_cases_deaths(filepath)[2])\n",
    "                daily_cases.append(get_cases_and_deaths_over_time(filepath)[0])\n",
    "                daily_deaths.append(get_cases_and_deaths_over_time(filepath)[1])\n",
    "    min_results_df[start_point] = [np.mean(dalys_per_run), np.mean(yll_per_run), np.mean(yld_per_run),\n",
    "                                   np.mean(mean_n_infected_per_host),\n",
    "                                   [np.mean(i) for i in zip(*distribution_of_infection_status)],\n",
    "                                   [np.mean(j) for i in zip(*cumsum_cases) for j in i],\n",
    "                                   [np.mean(i) for i in zip(*n_cases)],\n",
    "                                   [np.mean(i) + 1.96 * np.std(i) for i in zip(*n_cases)],\n",
    "                                   [np.mean(i) - 1.96 * np.std(i) for i in zip(*n_cases)],\n",
    "                                   [np.mean(j) for i in zip(*cumsum_deaths)for j in i],\n",
    "                                   [np.mean(i) for i in zip(*daily_deaths)],\n",
    "                                   ]\n",
    "\n",
    "max_results_df = pd.DataFrame()\n",
    "max_results_df.index = ['DALYs', 'YLL', 'YLD', 'mean_infected_per_host', 'dist_inf_status', 'cumulative_cases',\n",
    "                        'n_cases', 'up', 'low', 'cumulative_deaths', 'n_deaths']\n",
    "max_district_start_points = ['_d2_', '_d18_', '_d23_', '_d26_', '_d31_']\n",
    "for start_point in max_district_start_points:\n",
    "    dalys_per_run = []\n",
    "    yll_per_run = []\n",
    "    yld_per_run = []\n",
    "    n_infected_per_host = []\n",
    "    countinfected_per_host = []\n",
    "    mean_n_infected_per_host = []\n",
    "    distribution_of_infection_status = []\n",
    "    mean_time_spent_in_each_status = []\n",
    "    std_time_spent_in_each_status = []\n",
    "    disease_progression_df = pd.DataFrame()\n",
    "    cumsum_cases = []\n",
    "    cumsum_deaths = []\n",
    "    daily_cases = []\n",
    "    daily_deaths = []\n",
    "    n_cases = []\n",
    "    for idx, file in enumerate(os.listdir(max_directory)):\n",
    "        filename = os.fsdecode(file)\n",
    "        filepath = max_directory.decode() + filename\n",
    "\n",
    "        if start_point in filename:\n",
    "            if filename.startswith(\"infections\"):\n",
    "                dalys_per_run.append(calculate_number_of_dalys(filepath))\n",
    "                yll_per_run.append(calculate_number_of_yll_and_yld(filepath)[0])\n",
    "                yld_per_run.append(calculate_number_of_yll_and_yld(filepath)[1])\n",
    "                n_infected_per_host.append(\n",
    "                    get_distributions_of_number_of_infections_per_source(filepath,\n",
    "                                                                                            return_mean_std=True)[0]\n",
    "                )\n",
    "                countinfected_per_host.append(\n",
    "                    get_distributions_of_number_of_infections_per_source(filepath,\n",
    "                                                                                            return_mean_std=True)[1]\n",
    "                )\n",
    "                mean_n_infected_per_host.append(\n",
    "                    get_distributions_of_number_of_infections_per_source(filepath,\n",
    "                                                                                            return_mean_std=True)[2]\n",
    "                )\n",
    "                distribution_of_infection_status.append(get_final_infection_status(filepath))\n",
    "                mean_time_spent_in_each_status.append(extract_time_in_each_stage(filepath)[0])\n",
    "                std_time_spent_in_each_status.append(extract_time_in_each_stage(filepath)[1])\n",
    "                disease_progression_df[idx] = find_number_who_reached_each_stage_of_disease(filepath)\n",
    "            if filename.startswith(\"district_start_point\"):\n",
    "                cumsum_cases.append(get_cum_sum_cases_deaths(filepath)[0])\n",
    "                cumsum_deaths.append(get_cum_sum_cases_deaths(filepath)[1])\n",
    "                n_cases.append(get_cum_sum_cases_deaths(filepath)[2])\n",
    "                daily_cases.append(get_cases_and_deaths_over_time(filepath)[0])\n",
    "                daily_deaths.append(get_cases_and_deaths_over_time(filepath)[1])\n",
    "    max_results_df[start_point] = [np.mean(dalys_per_run), np.mean(yll_per_run), np.mean(yld_per_run),\n",
    "                                   np.mean(mean_n_infected_per_host),\n",
    "                                   [np.mean(i) for i in zip(*distribution_of_infection_status)],\n",
    "                                   [np.mean(j) for i in zip(*cumsum_cases) for j in i],\n",
    "                                   [np.mean(i) for i in zip(*n_cases)],\n",
    "                                   [np.mean(i) + 1.96 * np.std(i) for i in zip(*n_cases)],\n",
    "                                   [np.mean(i) - 1.96 * np.std(i) for i in zip(*n_cases)],\n",
    "                                   [np.mean(j) for i in zip(*cumsum_deaths)for j in i],\n",
    "                                   [np.mean(i) for i in zip(*daily_deaths)],\n",
    "                                   ]\n",
    "max_results_df.to_csv(\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/data/max_run_results.csv\")\n",
    "min_results_df.to_csv(\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/data/min_run_results.csv\")\n",
    "outbound_rankings = pd.read_csv(\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/data/\"\n",
    "                                \"Most mobile districts i5.csv\")\n",
    "matched_names = ['d_2', 'd_18', 'd_23', 'd_26', 'd_31']\n",
    "ranking_max = [int(outbound_rankings.loc[outbound_rankings['outbound_district'] == name, 'order'].values) + 1 for\n",
    "               name in matched_names]\n",
    "matched_names = ['d_29', 'd_39', 'd_41', 'd_42', 'd_51']\n",
    "ranking_min = [int(outbound_rankings.loc[outbound_rankings['outbound_district'] == name, 'order'].values) + 1 for\n",
    "               name in matched_names]\n",
    "flip_rank = [61 - i for i in ranking_min]\n",
    "max_results_df = pd.read_csv(\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/data/max_run_results.csv\")\n",
    "max_results_df.index = max_results_df['Unnamed: 0']\n",
    "max_results_df = max_results_df.drop('Unnamed: 0', axis=1)\n",
    "max_color = {'1': 'darkred',\n",
    "             '2': 'maroon',\n",
    "             '3': 'firebrick',\n",
    "             '4': 'brown',\n",
    "             '5': 'indianred'}\n",
    "min_color = {'1': 'blue',\n",
    "             '2': 'mediumblue',\n",
    "             '3': 'darkblue',\n",
    "             '4': 'navy',\n",
    "             '5': 'midnightblue'}\n",
    "min_results_df = pd.read_csv(\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/data/min_run_results.csv\")\n",
    "min_results_df.index = min_results_df['Unnamed: 0']\n",
    "min_results_df = min_results_df.drop('Unnamed: 0', axis=1)\n",
    "max_starting_districts = ''\n",
    "min_starting_districts = ''\n",
    "for column in max_results_df.columns:\n",
    "    plt.plot(np.arange(len(ast.literal_eval(max_results_df.loc['n_cases', column]))),\n",
    "             np.cumsum(ast.literal_eval(max_results_df.loc['n_cases', column])),\n",
    "             label=column[1:-1], color=max_color[str(max_results_df.loc['ranking', column])])\n",
    "    max_starting_districts += column\n",
    "for column in min_results_df.columns:\n",
    "    plt.plot(np.arange(len(ast.literal_eval(min_results_df.loc['n_cases', column]))),\n",
    "             np.cumsum(ast.literal_eval(min_results_df.loc['n_cases', column])),\n",
    "             label=column[1:-1], color=min_color[str(min_results_df.loc['ranking', column])])\n",
    "    min_starting_districts += column\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Cumulative number of cases')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('The cumulative number of cases for epidemics starting in different districts')\n",
    "plt.savefig(f\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/plots/\"\n",
    "            f\"cumulative_cases_per_district_start_{max_starting_districts + min_starting_districts}_batch_\"\n",
    "            f\"{30}_runs_log.png\",\n",
    "            bbox_inches='tight')\n",
    "plt.clf()\n",
    "\n",
    "for column in max_results_df.columns:\n",
    "    plt.plot(np.arange(len(ast.literal_eval(max_results_df.loc['n_cases', column]))),\n",
    "             ast.literal_eval(max_results_df.loc['n_cases', column]),\n",
    "             label=column[1:-1], color=max_color[str(max_results_df.loc['ranking', column])])\n",
    "for column in min_results_df.columns:\n",
    "    plt.plot(np.arange(len(ast.literal_eval(min_results_df.loc['n_cases', column]))),\n",
    "             ast.literal_eval(min_results_df.loc['n_cases', column]),\n",
    "             label=column[1:-1], color=min_color[str(min_results_df.loc['ranking', column])])\n",
    "plt.legend()\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Number of cases')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('The number of cases for epidemics starting in different districts')\n",
    "\n",
    "plt.savefig(f\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/plots/\"\n",
    "            f\"av_num_cases_per_district_start{max_starting_districts + min_starting_districts}_batch_\"\n",
    "            f\"{30}_runs_log.png\",\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.clf()\n",
    "dalys = list(max_results_df.loc['DALYs'].values.astype(float)) + \\\n",
    "        (list(min_results_df.loc['DALYs'].values.astype(float)))\n",
    "district_names = list(max_results_df.columns) + (list(min_results_df.columns))\n",
    "colors = list(max_color.values()) + list(min_color.values())\n",
    "plt.bar(np.arange(len(dalys)), dalys, color=colors)\n",
    "plt.xticks(np.arange(len(dalys)), district_names)\n",
    "plt.ylabel('DALYs (logscale)')\n",
    "plt.yscale('log')\n",
    "plt.title('DALYs per start region')\n",
    "plt.savefig(f\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/plots/\"\n",
    "            f\"av_DALYs_cases_per_district_start{max_starting_districts + min_starting_districts}_batch_\"\n",
    "            f\"{30}_runs_logscale.png\",\n",
    "            bbox_inches='tight')\n",
    "plt.clf()\n",
    "red_max_to_mid = np.linspace(256, 256 / 2 + 10, len(max_color.keys()))\n",
    "red_upper_scale = [[i / 256, 0, 0] for i in red_max_to_mid]\n",
    "red_mid_to_min = np.linspace(256 / 2, 100, len(max_color.keys()))\n",
    "red_lower_scale = [[i / 256, 0, 0] for i in red_mid_to_min]\n",
    "blue_max_to_mid = np.linspace(256, 256 / 2 + 10, len(max_color.keys()))\n",
    "blue_upper_scale = [[0, 0, i / 256] for i in blue_max_to_mid]\n",
    "blue_mid_to_min = np.linspace(256 / 2, 100, len(max_color.keys()))\n",
    "blue_lower_scale = [[0, 0, i / 256] for i in blue_mid_to_min]\n",
    "\n",
    "yll_data = list(max_results_df.loc['YLL'].values.astype(float)) + list(min_results_df.loc['YLL'].values.astype(float))\n",
    "yll_colors = red_upper_scale + blue_upper_scale\n",
    "yld_data = list(max_results_df.loc['YLD'].values.astype(float)) + list(min_results_df.loc['YLD'].values.astype(float))\n",
    "yld_colors = red_lower_scale + blue_lower_scale\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(np.arange(len(max_results_df.loc['YLL'].values.astype(float))),\n",
    "        list(max_results_df.loc['YLL'].values.astype(float)),\n",
    "        color=red_lower_scale[0], label='YLL')\n",
    "plt.bar(np.arange(len(max_results_df.loc['YLD'].values.astype(float))),\n",
    "        list(max_results_df.loc['YLD'].values.astype(float)),\n",
    "        color=red_upper_scale[1], label='YLD', bottom=list(max_results_df.loc['YLL'].values.astype(float)))\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(len(max_district_start_points)), max_district_start_points)\n",
    "plt.ylabel('DALYs')\n",
    "plt.title('Most mobile')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(np.arange(len(min_results_df.loc['YLL'].values.astype(float))),\n",
    "        list(min_results_df.loc['YLL'].values.astype(float)),\n",
    "        color=blue_lower_scale[1], label='YLL')\n",
    "plt.bar(np.arange(len(min_results_df.loc['YLD'].values.astype(float))),\n",
    "        list(min_results_df.loc['YLD'].values.astype(float)),\n",
    "        color=blue_upper_scale[1], label='YLD', bottom=list(min_results_df.loc['YLL'].values.astype(float)))\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(len(min_district_start_points)), min_district_start_points)\n",
    "plt.ylabel('DALYs')\n",
    "plt.title('Least mobile')\n",
    "plt.show()\n",
    "plt.bar(np.arange(len(yld_data)), yld_data, color=yld_colors, bottom=yll_data, label='YLD')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "for column in max_results_df.columns:\n",
    "    plt.plot(np.arange(len(ast.literal_eval(max_results_df.loc['n_deaths', column]))),\n",
    "             ast.literal_eval(max_results_df.loc['n_deaths', column]),\n",
    "             label=column[1:-1], color=max_color[str(max_results_df.loc['ranking', column])])\n",
    "for column in min_results_df.columns:\n",
    "    plt.plot(np.arange(len(ast.literal_eval(min_results_df.loc['n_deaths', column]))),\n",
    "             ast.literal_eval(min_results_df.loc['n_deaths', column]),\n",
    "             label=column[1:-1], color=min_color[str(min_results_df.loc['ranking', column])])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Number of deaths')\n",
    "plt.title('The number of deaths for epidemics starting in different districts')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.savefig(f\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/plots/\"\n",
    "            f\"av_num_deaths_per_district_start{max_starting_districts + min_starting_districts}_batch_\"\n",
    "            f\"{30}_runs_log.png\",\n",
    "            bbox_inches='tight')\n",
    "plt.clf()\n",
    "print('hi')\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "for column in max_results_df.columns:\n",
    "    plt.plot(np.arange(len(ast.literal_eval(max_results_df.loc['n_cases', column]))),\n",
    "             np.cumsum(ast.literal_eval(max_results_df.loc['n_cases', column])),\n",
    "             label=column[1:-1], color=max_color[str(max_results_df.loc['ranking', column])])\n",
    "plt.legend()\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Cumulative number of cases')\n",
    "plt.subplot(2, 1, 2)\n",
    "for column in min_results_df.columns:\n",
    "    plt.plot(np.arange(len(ast.literal_eval(min_results_df.loc['n_cases', column]))),\n",
    "             np.cumsum(ast.literal_eval(min_results_df.loc['n_cases', column])),\n",
    "             label=column[1:-1], color=min_color[str(min_results_df.loc['ranking', column])])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Cumulative number of cases')\n",
    "plt.suptitle('The cumulative number of cases in the\\nmost and least mobile districts respectively')\n",
    "plt.subplots_adjust(hspace=0.6)\n",
    "plt.savefig(f\"/Users/robbiework/PycharmProjects/spacialEpidemiologyAnalysis/plots/\"\n",
    "            f\"cumulative_cases_per_district_start_{max_starting_districts + min_starting_districts}_batch_\"\n",
    "            f\"{30}_runs_log.png\",\n",
    "            bbox_inches='tight')\n",
    "\n",
    "plt.clf()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
